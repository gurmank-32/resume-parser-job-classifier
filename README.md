# Resume Parser and Job Classifier
An end-to-end NLP-based machine learning application that parses resumes in PDF format, extracts relevant information, and recommends the top 3 most suitable job roles using probabilistic classification.
This project simulates how Applicant Tracking Systems (ATS) and job-matching platforms analyze resumes in real-world hiring pipelines.

---

ğŸš€ Features
- ğŸ“¥ Upload resumes in PDF format
- ğŸ§  Extract and clean unstructured resume text using spaCy
- ğŸ“Š Classify resumes into job roles using NLP & Machine Learning
- ğŸ† Recommend Top-3 matching job roles with confidence scores
- ğŸ§° Extract skills using keyword-based matching
- ğŸ“ˆ Display resume statistics (word count, skill count)
- ğŸŒ Interactive web interface built with Streamlit

---

### ğŸ§  Project Architecture

**Resume (PDF)**  
â†“  
**PyPDF2 (Text Extraction)**  
â†“  
**spaCy NLP Pipeline (Cleaning & Lemmatization)**  
â†“  
**TF-IDF Vectorization**  
â†“  
**Logistic Regression Classifier**  
â†“  
**Top-3 Job Role Predictions + Skills**  
â†“  
**Streamlit Web Application**

---

## ğŸ› ï¸ Tech Stack

| Category       | Tools                  |
|----------------|-----------------------|
| Language       | Python                |
| NLP (Natural Language Processing)            | spaCy                 |
| ML             | scikit-learn          |
| PDF Parsing    | PyPDF2                |
| Vectorization  | TF-IDF (Term Frequency-Inverse Document Frequency)               |
| Model          | Logistic Regression   |
| Deployment     | Streamlit             |

---
## ğŸ“‚ Project Structure

resume-parser-job-classifier/  
â”‚  
â”œâ”€â”€ app.py                  # ğŸŒ Streamlit application  
â”œâ”€â”€ model.py                # ğŸ§  Model training script  
â”œâ”€â”€ parser.py               # ğŸ§¹ Resume text extraction & cleaning  
â”œâ”€â”€ features.py             # ğŸ› ï¸ Skill extraction & resume stats  
â”œâ”€â”€ resume_classifier.pkl   # ğŸ¤– Trained ML model  
â”œâ”€â”€ data/  
â”‚   â””â”€â”€ resumes/  
â”‚       â””â”€â”€ resume_data.csv # ğŸ“Š Kaggle dataset  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md  

---

## ğŸ“Š Dataset

**Source:** Kaggle Resume Dataset  
Contains structured resume information such as:  

- Skills  
- Career objectives  
- Education  
- Experience  
- Job roles (labels)  

**Training Labels**  

- `X (Features)`: Combined resume text fields  
- `y (Target)`: Job role / position name  

---

## ğŸ§ª Model Details

- **Text Representation:** TF-IDF (unigrams + bigrams)  
- **Classifier:** Logistic Regression (multi-class)  
- **Prediction Strategy:** Top-3 roles using probability distribution (`predict_proba`)  

**Why Top-3?**  
- Resumes often span multiple roles  
- Improves realism and interpretability  

---

## ğŸ“¸ Sample Output

-ğŸ† Top-3 Matching Job Roles
  - Data Engineer â€” Confidence: 0.07
  - Data Scientist â€” Confidence: 0.06
  - Big Data Analyst â€” Confidence: 0.06
    
- ğŸ› ï¸ Extracted Skills
  - Programming: Python, Java, SQL
  - Data: Machine Learning, Spark
  - Tools: AWS, Git

---
ğŸ¯ Why This Project?
- ğŸ—ï¸ Demonstrates end-to-end ML system design
- ğŸ§¹ Handles real-world noisy text data
- ğŸ§  Emphasizes interpretability over blind accuracy
- ğŸŒ Mimics real hiring recommendation systems

---
ğŸ”® Future Enhancements
- ğŸ” Explainable AI (highlight keywords influencing predictions)
- ğŸ¤– BERT / Sentence Transformer embeddings
- âš–ï¸ Class imbalance handling
- ğŸ“Š Model evaluation dashboard
- â˜ï¸ Cloud deployment

---

## ğŸ’» How to Run the Project

1ï¸âƒ£ **Clone the repository**

2ï¸âƒ£ **Install dependencies**
   - pip install -r requirements.txt
   - python -m spacy download en_core_web_sm

3ï¸âƒ£ **Run the Streamlit app**
   - streamlit run app.py

---
